---
title: "Project2"
author: "Vivek Garg"
output: html_document
date: "2024-11-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos = c(CRAN = "https://cloud.r-project.org"))
```
# Introduction
For this project I created my own dataset. I used the Yahoo Finance API and Python to scrape the S&P 500 company list, the Russell 2000, and the the S&P 400 to get a mix of small, mid, and large cap stocks. I then selected 1000 companies at random from this aggregated list. I then used the Yahoo API and Finnhub to get the financial data for the companies and put it into a CSV. Github Link to process: . 


The objective of this project is to develop a predictive model that estimates the Recent Close Price of stocks based on various market and financial variables. I hope to answer the following questions.\\
  1. What are the most significant predictors of stock prices?
  
  2. How do market variables interact to influence stock prices? I want to see which variables have interaction effects.
  
  3. Can we predict stock price trends accurately? I want to see if we can get a good R^2 value which means we can use historical data values to predict current prices.
  
By developing and validating this model, the goal is to generate insights into the economic drivers of stock prices, which can potentially inform investment strategies or financial decision-making.

## Description of Variables
Ticker: Identifier for the stock (not used as a predictor).
Sector: Categorical variable indicating the sector.
Industry: Categorical variable indicating the industry.
Region: Categorical variable indicating the region.(not used as a predictor because "North America" for all)
Market Cap Classification: Categorical variable indicating the market cap classification.
Volatility Classification: Categorical variable indicating the volatility classification.
Growth vs Value: Categorical variable indicating growth or value classification.
P/E Ratio: Quantitative variable representing the price-to-earnings ratio.
Dividend Yield (%): Quantitative variable representing the dividend yield.
Beta: Quantitative variable representing the stock's volatility relative to the market.
Avg Volume: Quantitative variable representing the average trading volume.
Recent.Close.Price: Quantitative variable representing the most recent closing price. (target)
EPS: Quantitative variable indicating the portion of a company's profit allocated to each share.
Revenue: Quantitative variable indicating the company's revenue.
Net Income: Quantitative variable indicating the net profit.
Debt-to-Equity Ratio: Quantitative variable comparing a company's total liabilities to its equity
ROE: Quantitative var calculating how much profit a company generates with shareholder money
P/B Ratio: Quantitative var calculating how much profit a company generates with shareholder money
Free Cash Flow: Quantitative var comparing a company's market value to its book value.
Analyst Ratings: Categorical Variable that I got from finnhub API based on ratings from analysts
Insider Transactions: Categorical Variable (finnhub API) that indicated insider transactions
## R Libraries and Helper Functions
```{r libraries, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(tidyr)
library(dplyr)
library(Boruta)
library(doParallel)
library(car)
library(lmtest)
library(caret)
library(olsrr)
library(MASS)
library(margins)
library(corrplot)
library(effects)
```
```{r helper functions}
# i like using helper function because it makes my code more modular and thats how i write my CS programs
#this is to calculate optimal number of bins for a histogram
helper.calculate_bins_sturges <- function(data) {
  n <- nrow(data)
  bins <- ceiling(log2(n) + 1)
  bins
  return(bins)
}


# this is a helper that can plot either a one variable histogram or many variables from the same dataset through facet_wrap
helper.plot_histograms <- function(data, color = "blue", bins = NULL, variable_name = NULL) {
  if (is.null(bins)) {
    bins <- helper.calculate_bins_sturges(data)
  }
  if (!is.null(variable_name)) {
    ggplot(data, aes(x = .data[[variable_name]])) + 
      geom_histogram(bins = bins, fill = color, alpha = 0.7) + 
      theme_minimal() + 
      labs(title = paste("Distribution of", variable_name))
  } else {
    #another debugging
    if (!all(c("Variable", "Value") %in% names(data))) {
      stop("Data must contain 'Variable' and 'Value' columns for multi-variable plotting.")
    }
    ggplot(data, aes(x = Value)) + 
      geom_histogram(bins = bins, fill = color, alpha = 0.7) + 
      facet_wrap(~ Variable, scales = "free") + 
      theme_minimal() + 
      labs(title = "Distribution of Predictors")
  }
}


#box plot basic helper using ggplot
helper.create_boxplot <- function(data, x_var, y_var = NULL, fill_color = "blue", title_prefix = "Latest Closing") {
  if (!is.null(y_var)) {
    ggplot(data, aes_string(x = x_var, y = y_var)) +
      geom_boxplot(fill = fill_color, alpha = 0.7) +
      theme_minimal() +
      labs(title = paste(title_prefix, y_var, "by", x_var), x = x_var, y = y_var)
  } else {
    return (Boxplot(as.formula(paste("~", x_var)), data = data, col = fill_color))
  }
}

# helper function for summary for categorical/factor variables
helper.group_summary <- function(data, group_var, target_var) {
  data %>%
    group_by(across(all_of(group_var))) %>%
    summarise(
      mean = mean(.data[[target_var]], na.rm = TRUE),
      sd = sd(.data[[target_var]], na.rm = TRUE),
      n = n()
    ) %>%
    arrange(desc(mean))
}

# helper function for anova for basic EDA of factor_variables
helper.run_anova <- function(data, factor_var, target_var) {
  formula <- as.formula(paste(target_var, "~", factor_var)) #s/o CS131
  anova_result <- aov(formula, data = data)
  summary(anova_result)
}

helper.eda_factor <- function(data, factor_var, target_var, color){
  #this gives the boxplot
  print(helper.create_boxplot(data, factor_var, target_var, color))
  
  #now annova
  print(helper.run_anova(data, factor_var, target_var))
  
  #finally summary
  helper.group_summary(data, factor_var, target_var)
}

helper.analyze_variable <- function(data, var_name, dependent_var = "Recent.Close.Price") {

  # histogram with normal and density curves
  print(helper.plot_histograms(data = data, variable_name = var_name))
  
  # 2. QQ Plot
  p2 <- ggplot(data, aes(sample = .data[[var_name]])) +
    stat_qq() +
    stat_qq_line(color = "red") +
    theme_minimal() +
    labs(title = paste("Q-Q Plot of", var_name))
  print(p2)
  
  # Box Plot
  p3 <- helper.create_boxplot(data = data, x_var = var_name)
  
  # density Plot
  p5 <- ggplot(data, aes_string(x = var_name)) +
        geom_density(fill = "lightblue", alpha = 0.7) +
        stat_function(fun = dnorm, 
                      args = list(mean = mean(data[[var_name]], na.rm = TRUE),
                                  sd = sd(data[[var_name]], na.rm = TRUE)),
                      color = "red", linewidth = 1) +
        theme_minimal() +
        labs(title = paste("Density Plot of", var_name),
             x = var_name,
             y = "Density")
  print(p5)

  
  # Print summary statistics
  cat("\nSummary Statistics for", var_name, ":\n")
  print(summary(data[[var_name]]))
}


detect_nonlinearities_and_outliers <- function(data, dependent_var, predictor_var) {
  # Helper: Perform power transformation and return lambda
  get_power_transform <- function(data, predictor_var) {
    formula <- as.formula(paste(predictor_var, "~", 1))
    power_transform <- powerTransform(formula, data = data)
    lambda <-power_transform$lambda
    return(lambda)
  }
  
  # Helper: Detect influential outliers using Cook's distance
  detect_outliers <- function(model, data) {
    cooks_d <- cooks.distance(model)
    threshold <- 4 * mean(cooks_d, na.rm = TRUE)
    influential_points <- which(cooks_d > threshold)
    outliers <- data[influential_points, ]
    return(list(outliers = outliers, cooks_d = cooks_d))
  }
  
  # Step 1: Power Transformation
  lambda <- get_power_transform(data, predictor_var)
  transformed_var <- paste0(predictor_var, "_transformed")
  data[[transformed_var]] <- bcPower(data[[predictor_var]], lambda)
  
  # Step 2: Fit the three models
  model1 <- lm(as.formula(paste(dependent_var, "~", predictor_var)), data = data)
  model2 <- lm(as.formula(paste(dependent_var, "~", transformed_var)), data = data)
  
  # Detect outliers for Model 1
  outlier_info <- detect_outliers(model1, data)
  data_without_outliers <- anti_join(data, outlier_info$outliers, by = names(data))
  model3 <- lm(as.formula(paste(dependent_var, "~", predictor_var)), data = data_without_outliers)
  
  # Step 3: Summarize models
  model_summaries <- list(
    base_model = summary(model1),
    transformed_model = summary(model2),
    model_without_outliers = summary(model3)
  )
  
  # Step 4: Visualization
  par(mfrow = c(2, 2))  # Set up 2x2 plotting area
  
  # Scatterplot: Original vs. Transformed Predictor
  plot(data[[predictor_var]], data[[transformed_var]], 
       main = "Original vs Transformed Predictor", 
       xlab = predictor_var, 
       ylab = transformed_var)
  
  # Residual plots for Model 1
  plot(residuals(model1), main = "Residuals of Base Model", xlab = "Index", ylab = "Residuals")
  
  # Residual plots for Model 3 (without outliers)
  plot(residuals(model3), main = "Residuals of Model w/o Outliers", xlab = "Index", ylab = "Residuals")
  
  # Cook's distance plot
  plot(outlier_info$cooks_d, type = "h", main = "Cook's Distance", 
       xlab = "Index", ylab = "Cook's Distance")
  abline(h = 3 * mean(outlier_info$cooks_d, na.rm = TRUE), col = "red", lty = 2)
  
  
  # Plot the models themselves
  par(mfrow = c(2, 2))  # Reset plotting area
  plot(model1, main = "Base Model")
  plot(model2, main = "Transformed Model")
  plot(model3, main = "Model without Outliers")
  
  # Scatterplots for each model
  p1 <- ggplot(data, aes_string(x = predictor_var, y = dependent_var)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "blue", se = TRUE) +
    theme_minimal() +
    labs(title = "Base Model",
         x = predictor_var,
         y = dependent_var)
  
  p2 <- ggplot(data, aes_string(x = transformed_var, y = dependent_var)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "blue", se = TRUE) +
    theme_minimal() +
    labs(title = "Transformed Model",
         x = transformed_var,
         y = dependent_var)
  
  p3 <- ggplot(data_without_outliers, aes_string(x = predictor_var, y = dependent_var)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "blue", se = TRUE) +
    theme_minimal() +
    labs(title = "Model without Outliers",
         x = predictor_var,
         y = dependent_var)
  
  gridExtra::grid.arrange(p1, p2, p3, ncol = 1)
  
  # Step 5: Return results
  results <- list(
    lambda = lambda,
    model_summaries = model_summaries,
    influential_outliers = outlier_info$outliers,
    data_without_outliers = data_without_outliers
  )
  
  return(results)
}


helper.remove_specific_rows <- function(data, var1_pattern, var2_pattern) {
  # Create logical index for rows to keep
  keep_rows <- !(grepl(var1_pattern, data$var1) & grepl(var2_pattern, data$var2) |
                 grepl(var1_pattern, data$var2) & grepl(var2_pattern, data$var1))
  
  # Subset the data to keep only the desired rows
  filtered_data <- data[keep_rows, ]
  
  return(filtered_data)
}

helper.diagnostic_plots <- function(model) {
  par(mfrow = c(2, 2))  # Set up a 2x2 plotting layout
  
  # 1. Cook's Distance Plot
  plot(model, which = 4, main = "Cook's Distance Plot")
  abline(h = 4/length(model$residuals), col = "red", lty = 2)  # Add threshold line
  legend("topright", legend = "Threshold: 4/n", col = "red", lty = 2, bty = "n")
  
  # 2. Residuals vs Fitted Plot
  plot(model$fitted.values, model$residuals, 
       main = "Residuals vs Fitted",
       xlab = "Fitted Values", ylab = "Residuals", pch = 20, col = "blue")
  abline(h = 0, col = "red", lty = 2)
  
  # 3. QQ-Plot
  qqnorm(model$residuals, main = "QQ-Plot")
  qqline(model$residuals, col = "red", lty = 2)
  
}



```

## Data Preprocessing and Set-up
```{r data preprocessing}
stock_data <- read.csv("enhanced_stock_dataset.csv")
na_counts_base <- colSums(is.na(stock_data))
print(na_counts_base)
stock_data <- na.omit(stock_data)

if (sum(is.na(stock_data)) > 0) {
  print("missing values present in data")
  #double checking no missing values in data
}
 stock_data$X52.Week.High <- NULL
 stock_data$X52.Week.Low <- NULL
 stock_data$Market.Cap <- NULL
helper.plot_histograms( data = stock_data, color = "green", variable_name = "Recent.Close.Price")
```
# 1 Variable Selection
### Boruta Algorithm Selection
```{r Boruta Selection}
set.seed(123)
# for some reason R is single threaded for BORUTA so we will set up threading manually because i am not waiting for boruta analysis 
cl <- makeCluster(detectCores() - 1) # Use all but one core
registerDoParallel(cl)

boruta_result_stock <- Boruta(Recent.Close.Price ~ ., data = stock_data, doTrace = 2)

#stop cluster 
stopCluster(cl)
registerDoSEQ()

plot(boruta_result_stock, xlab = "", xaxt = "n", main = "Variable Importance via Boruta")
lz_stock <- lapply(1:ncol(boruta_result_stock$ImpHistory), function(i)
  boruta_result_stock$ImpHistory[is.finite(boruta_result_stock$ImpHistory[, i]), i])
names(lz_stock) <- colnames(boruta_result_stock$ImpHistory)
Labels_stock <- sort(sapply(lz_stock, median))
axis(side = 1, las = 2, labels = names(Labels_stock),
     at = 1:ncol(boruta_result_stock$ImpHistory), cex.axis = 0.7)


important_vars_stock <- getSelectedAttributes(boruta_result_stock, withTentative = TRUE)
importance_scores_stock <- attStats(boruta_result_stock)


sorted_scores_stock <- importance_scores_stock[order(-importance_scores_stock$meanImp), ]
print(sorted_scores_stock)

quantitative_vars <- names(stock_data)[sapply(stock_data, is.numeric)]
top_quantitative_scores <- sorted_scores_stock[rownames(sorted_scores_stock) %in% quantitative_vars, ]
top_5_vars_stock <- rownames(top_quantitative_scores)[1:5]
print(top_5_vars_stock)
```

I ran Boruta on the variables and was able to come up with 5 quantitative variables that would be best suited for my MLR model. I chose the five highest quantitative variables by meanImportance from the Boruta model. The five variables I will be choosing are `"EPS"`, `"P.E.Ratio"`, `"P.B.Ratio"`, `"Avg.Volume"`, `"Net.Income"`.

### Factor Variable Selection
```{r EDA for factor variables}
# R is pretty cool because it auto does one-hot encoding for factor variables so that saves us a little code


#this is doing all of the EDA for our factor variables 
helper.eda_factor(stock_data, "Sector", "Recent.Close.Price", "blue")
helper.eda_factor(stock_data, "Industry", "Recent.Close.Price", "green")
helper.eda_factor(stock_data, "Market.Cap.Classification", "Recent.Close.Price", "purple")
helper.eda_factor(stock_data, "Volatility.Classification", "Recent.Close.Price", "lightblue")
helper.eda_factor(stock_data, "Growth.vs.Value", "Recent.Close.Price", "darkblue")
helper.eda_factor(stock_data, "Analyst.Ratings", "Recent.Close.Price", "pink")
helper.eda_factor(stock_data, "Insider.Transactions", "Recent.Close.Price", "yellow")



```

After conducting EDA for all of our factor variables, there are only two variables that I feel comfortable selecting. The first is `Market.Cap.Classification` and the second is `Growth.vs.Value`. I eliminated Industry first as it has too many categories and would just overfit our model despite its low p-value from the ANOVA test. I then elimated Analyst.Ratings and Insider.Transactions due to them having non-significant p-values through ANOVA. Then I was left with 4 other variables but both `Sector` and `Volatility.Classification` both were rejected by Boruta and had higher p-values then the chosen variables which is why I chose to reject them. I was at first surprised by `Sector` failing Boruta, but then I realized that stock price is not an indication of growth rates in a sector and since we have no growth variables, the strong performance of technology stocks this year compared to energy stocks was not leveraged the way I thought it would be. 

# 2. Descriptive Analysis
##Analysis for EPS
```{r Descriptive Analysis for EPS}

helper.analyze_variable(stock_data, "EPS")


```

```{r outlier and linearity detection for EPS}
results <- detect_nonlinearities_and_outliers(
  data = stock_data, 
  dependent_var = "Recent.Close.Price", 
  predictor_var = "EPS"
)

# Output results
print("Optimal Lambda from powerTransform")
results$lambda  # Optimal lambda
results$model_summaries  # Summaries of the three models
results$influential_outliers # Name of the outliers

```
In my opinion for EPS there is no reason to do a powerTransform as the R^2 values after the powerTransform actually decreases and although it definately makes it more normally distributed, I do not think it is statistically significant in the premise of making a multiple linear regression model. The next question then comes to outliers. We used Cook's Distance to show that we have 10 outliers in our model that we identified that have a standard deviation of greater than 4 then our mean Cook's Distance. I do not think it is worth removing these outliers however as the R^2 does not change drastically with their exclusion.

## Analysis for PB Ratio
```{r Descriptive Analysis for PB Ratio}

helper.analyze_variable(stock_data, "P.B.Ratio")

```


```{r outlier and linearity detection for PB Ratio}
results <- detect_nonlinearities_and_outliers(
  data = stock_data, 
  dependent_var = "Recent.Close.Price", 
  predictor_var = "P.B.Ratio"
)

# Output results
print("Optimal Lambda from powerTransform")
results$lambda  # Optimal lambda
results$model_summaries  # Summaries of the three models
results$influential_outliers # Name of the outliers

```

In my opinion for PB ratio there is a reason to do a powerTransform as the R^2 values after the powerTransform actually increases by a significant amount and it definitely makes it more normally distributed. I would argue this transformation is helpful in making our model more predictive. The one question that I had was that it leads to us having a negative PB ratio for some instances which economically infeasible, but at the same time because this is a transformed variable I do not think this is an issue as all of the variables would be scaled with this transformation. The next question then comes to outliers. We used Cook's Distance to show that we have 6 outliers in our model that we identified that have a standard deviation of greater than 4 then our mean Cook's Distance. I do not think it is worth removing these outliers however as the R^2 does not change drastically with their exclusion and is actually lower then the transformed linear model.
## Analysis for PE Ratio
```{r Descriptive Analysis for PE Ratio}

helper.analyze_variable(stock_data, "P.E.Ratio")

```


```{r outlier and linearity detection for PE Ratio}
results <- detect_nonlinearities_and_outliers(
  data = stock_data, 
  dependent_var = "Recent.Close.Price", 
  predictor_var = "P.E.Ratio"
)

# Output results
print("Optimal Lambda from powerTransform")
results$lambda  # Optimal lambda
results$model_summaries  # Summaries of the three models
results$influential_outliers # Name of the outliers

```

In my opinion for PE ratio there is a reason to do a powerTransform. This is because when we have the base model without outliers the linear model does not even think PE Ratio is a statistically significant variable, but the transformed model says that we do. We know this as the p value is less than 0.05. This is why from now on I will be proceeding with the transformed version of PE for the most part. The next question then comes to outliers. We used Cook's Distance to show that we have 21 outliers in our model that we identified that have a standard deviation of greater than 4 then our mean Cook's Distance. I do not think it is worth removing these outliers however as the R^2 does not change drastically with their exclusion and is actually lower then the transformed linear model. Additionally that would mean removing around 5% of our data which would be a lot. 


## Analysis for Avg Volume
```{r Descriptive Analysis for Avg Volume}

helper.analyze_variable(stock_data, "Avg.Volume")

```


```{r outlier and linearity detection for Avg Volume}
data = stock_data
dependent_var = "Recent.Close.Price"
predictor_var = "Avg.Volume"
results <- detect_nonlinearities_and_outliers(
  data = stock_data, 
  dependent_var = "Recent.Close.Price", 
  predictor_var = "Avg.Volume"
)


# Output results
print("Optimal Lambda from powerTransform")
results$lambda  # Optimal lambda
results$model_summaries  # Summaries of the three models
results$influential_outliers # Name of the outliers


## With this variable a log transformation is also a valid transform so as a result we will test it
data <- stock_data
log_transformed_var <- paste0(predictor_var, "_Log") #take adv of R's env manager
data[[log_transformed_var]] <- log(stock_data[[predictor_var]])
model4 <- lm(as.formula(paste(dependent_var, "~", log_transformed_var)), data = data)
par(mfrow = c(2, 2))
plot(model4, main = "Model with Log Transform")
summary(model4)
p4 <- ggplot(data, aes_string(x = log_transformed_var, y = dependent_var)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "blue", se = TRUE) +
    theme_minimal() +
    labs(title = "Log Model",
         x = predictor_var,
         y = dependent_var)
print(p4)


```

This variable will likely not be used in future analysis as none of the linear models (base, transformed, or outlier removed) demonstrate statistical significance. This means that this variable, while passing Boruta, does not show much promise. I will continue to use the base variable when I try different models with it, but as of now it looks like I will not be using it in the future. It is important to note here that log transform also worked along with the ideal transform so I tested both here. 


## Analysis for Net Income
```{r Descriptive Analysis for Net Income}

helper.analyze_variable(stock_data, "Net.Income")

```


```{r outlier and linearity detection for Net Income}
data = stock_data 
dependent_var = "Recent.Close.Price"
predictor_var = "Net.Income"
results <- detect_nonlinearities_and_outliers(
  data = stock_data, 
  dependent_var = "Recent.Close.Price", 
  predictor_var = "Net.Income"
)

# Output results
print("Optimal Lambda from powerTransform")
results$lambda  # Optimal lambda
results$model_summaries  # Summaries of the three models
results$influential_outliers # Name of the outliers


## With this variable a log transformation is also a valid transform so as a result we will test it
data <- stock_data
log_transformed_var <- paste0(predictor_var, "_Log") #take adv of R's env manager
data[[log_transformed_var]] <- log(stock_data[[predictor_var]])
model4 <- lm(as.formula(paste(dependent_var, "~", log_transformed_var)), data = data)
par(mfrow = c(2, 2))
plot(model4, main = "Model with Log Transform")
summary(model4)
p4 <- ggplot(data, aes_string(x = log_transformed_var, y = dependent_var)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "blue", se = TRUE) +
    theme_minimal() +
    labs(title = "Log Model",
         x = predictor_var,
         y = dependent_var)
print(p4)
stock_data$Net.Income_log = log(stock_data$Net.Income)
```
For NetIncome I will use a log transform as it gives the highest R-squared and it is a transformation that I am comfortable using. Additionally it does cause a loss of ecnomic understanding as it does not lead to negative values. In the sense of outliers I do not think it is worth trying to remove the four values as they do not lead to a statistically significant difference between R-squared of the base model and the outlier removed model. 
## Descriptive Analysis of Factor Variables
Please refer to section 1 for boxplots and ANOVA analysis of the chosen factor variables. There do not exist density plots for factor variables and additionally, linearity and outliers are not a concern with factor variables. 
## Correlation Analysis
```{r correlation plot}
factor_vars <- c("Market.Cap.Classification", "Growth.vs.Value")
selected_vars <- c(factor_vars, top_5_vars_stock)

correlation_data_set <- stock_data[selected_vars]
correlation_data_set$Market.Cap.Classification <- as.factor(correlation_data_set$Market.Cap.Classification)
correlation_data_set$Growth.vs.Value <- as.factor(correlation_data_set$Growth.vs.Value)
correlation_test <- data.frame(lapply(correlation_data_set, function(x) {
  if (is.factor(x)) as.numeric(x) else x
}))
cor_matrix <- cor(correlation_test, use = "complete.obs")

strong_correlations <- which(abs(cor_matrix) > 0.8 & abs(cor_matrix) < 1, arr.ind = TRUE)
strong_pairs <- data.frame(
  Var1 = rownames(cor_matrix)[strong_correlations[, 1]],
  Var2 = colnames(cor_matrix)[strong_correlations[, 2]],
  Correlation = cor_matrix[strong_correlations]
)
print(strong_pairs)


# Plot the correlation matrix this is hard to view due to the 21 variables but it still somewhat useful to see
corrplot(cor_matrix, method = "color", type = "upper", order = "hclust",
         tl.col = "black", tl.srt = 45)

```

There appears to be no variables with high correlation between one another. This means that we can proceed with our linear model with all of our varaibles without having to worry about multicolinearity. I prefer using a correlation matrix over VIF because I am more comfortable with the math behind this one, and I have used it more often. I will still use VIF in step 3.
# 3
## Initial Model Building
```{r initial model and var defintions}
# i wanna be able to use this variable when making my models
formula <- as.formula(paste("Recent.Close.Price ~", paste(selected_vars, collapse = " + ")))
# idw deal with selecting only my chosen vars
model_data <- stock_data[, c("Recent.Close.Price", selected_vars)]
model_data$Net.Income_log <- log(model_data$Net.Income)
# making sure factor vars so we get one off encoding for free
model_data$Market.Cap.Classification <- as.factor(model_data$Market.Cap.Classification)
model_data$Growth.vs.Value <- as.factor(model_data$Growth.vs.Value)

initial_model <- lm(formula, data = model_data)
par(mfrow = c(2, 2))  # Reset plotting area
plot(initial_model, main = "Initial Model")
summary(initial_model)
```
From the initial model we can eliminate `Avg.Volume` and `Net.Income` as they have p-values of over 0.05. We have a pretty good R^2 value for stock prediction however. We will test it later with `Net.Income_Log` however.
### VIF testing
```{r VIF}
vif_values <- vif(initial_model)
print(vif_values)
```
There is nothing that has high multi-colinearity which is the same as the results from the correlation matrix.
## Testing initial model with Net.Income_log and without Avg.Volume
```{r Model 2 test}
quantitative_vars <- c("EPS", "P.E.Ratio", "P.B.Ratio", "Net.Income_log")
selected_vars <- c(factor_vars, quantitative_vars)
formula <- as.formula(paste("Recent.Close.Price ~", paste(selected_vars, collapse = " + ")))
model_2 <- lm(formula, data = model_data)
par(mfrow = c(2, 2))  # Reset plotting area
plot(model_2, main = "Model 2")
summary(model_2)
```
After testing this model we can see that even `Net.Income_log` is still not statistically significant and the inclusion of it does not change the R^2 value by a statistically significant value meaning I will be exclusing `Net.Income_log` and `Net.Income` from future models.
## Testing Model 3 with only 3 quantiative variables
```{r Model 3 test}
model_data$Avg.Volume <- NULL
model_data$Net.Income <- NULL
model_data$Net.Income_log <- NULL
quantitative_vars <- c("EPS", "P.E.Ratio", "P.B.Ratio")
selected_vars <- c(factor_vars, quantitative_vars)
formula <- as.formula(paste("Recent.Close.Price ~", paste(selected_vars, collapse = " + ")))
model_3 <- lm(formula, data = model_data)
par(mfrow = c(2, 2))  # Reset plotting area
plot(model_3, main = "Model 3")
summary(model_3)
```
So far every single one of these variables are statistically significant so as a result we will proceed with this model for further analysis. Moreover we will be testing these variables with the Ramsey RESET test for model misspecefication and have omitted the two other variables from future consideration and testing.
## Testing Model Misspecification
```{r Ramsey Reset test}
resettest(model_3, power = 2, type = "regressor")
resettest(model_3, power = 3, type = "regressor")

```
It appears that we need to do a non-linear transformation for at least one of the quantiative variables so we will be trying that for the next slide.
### testing each of the selected variables to see if a transformation is needed
```{r looping through vars}
for (var in quantitative_vars) {
  # Define formulas
  formula_test_square <- as.formula(paste("Recent.Close.Price ~", 
                                          paste(selected_vars, collapse = " + "), 
                                          "+ I(", var, "^2)"))
  formula_test_both <- as.formula(paste("Recent.Close.Price ~", 
                                        paste(selected_vars, collapse = " + "), 
                                        "+ I(", var, "^2) + I(", var, "^3)"))
  formula_test_cube <- as.formula(paste("Recent.Close.Price ~", 
                                        paste(selected_vars, collapse = " + "), 
                                        "+ I(", var, "^3)"))
  formula_test_no_linear <- as.formula(paste("Recent.Close.Price ~", 
                                             paste(selected_vars, collapse = " + "), 
                                             "+ I(", var, "^2) + I(", var, "^3) -", var))
  
  # Fit models
  model_test_square <- lm(formula_test_square, data = model_data)
  model_test_both <- lm(formula_test_both, data = model_data)
  model_test_cube <- lm(formula_test_cube, data = model_data)
  model_test_no_linear <- lm(formula_test_no_linear, data = model_data)
  
  # Print BIC values
  print(paste("Testing non-linearity for variable:", var))
  print(BIC(model_3, model_test_square, model_test_cube, model_test_both, model_test_no_linear))
  
  # Extract R-squared and Adjusted R-squared values
  r_squared_values <- c(
    summary(model_test_square)$r.squared,
    summary(model_test_cube)$r.squared,
    summary(model_test_both)$r.squared,
    summary(model_test_no_linear)$r.squared
  )
  
  adj_r_squared_values <- c(
    summary(model_test_square)$adj.r.squared,
    summary(model_test_cube)$adj.r.squared,
    summary(model_test_both)$adj.r.squared,
    summary(model_test_no_linear)$adj.r.squared
  )
  
  # Print R-squared and Adjusted R-squared values
  print(paste("R-squared values for models with", var, ":"))
  print(r_squared_values)
  
  print(paste("Adjusted R-squared values for models with", var, ":"))
  print(adj_r_squared_values)
}
```
It appears through testing of trying square and cube powers of the quantitative variables that for all of our variables we would prefer a model that includes a linear, quadratic, and cubic, representation of each variable. We have BIC and adjusted R^2 values of our individual model, but now we will combine the different models to figure out which one is the best representation. So far the best model in terms of BIC is `model_test_both` with `P.B.Ratio` being transformed only with an BIC of 4959.054 All further models will be tested against this it also has adjusted R^2 of 0.7085542. We are using BIC instead of AIC right now because we want to focus on selecting the best possible model for our current data, because we are not planning on doing any forecasting. We will use AIC at the end however to confirm our selections.  
### Testing possible Permutations to find best model through AIC and adjusted R^2
```{r testing permutations}
# Function to fit models and compare adjusted R-squared values
compare_models <- function(data, dependent_var, pairs) {
  results <- list()
  for (pair in pairs) {
    var1 <- pair[1]
    var2 <- pair[2]
    
    # Define formulas
    formula_test <- as.formula(paste(dependent_var, "~", 
                                     paste(selected_vars, collapse = " + "), 
                                     "+ I(", var1, "^2) + I(", var1, "^3) + I(", var2, "^2) + I(", var2, "^3)"))
    
    # fit our model
    model_test <- lm(formula_test, data = data)
    
    
    adj_r_squared <- summary(model_test)$adj.r.squared
    bic_result  <- BIC(model_test)
    
    # store results
    results[[paste(var1, var2, sep = "_")]] <- list(adj_r_squared = adj_r_squared, BIC = bic_result)
  }
  
  # now doing for all three
  var1 <- quantitative_vars[1]
  var2 <- quantitative_vars[2]
  var3 <- quantitative_vars[3]
  formula_test <- as.formula(paste("Recent.Close.Price ~", 
                                 paste(selected_vars, collapse = " + "), 
                                 "+ I(", var1, "^2) + I(", var1, "^3) + I(", var2, "^2) + I(", var2, "^3) + I(", var3, "^2) + I(", var3,
                                 "^3)"))
 
  model_test <- lm(formula_test, data = data)
  adj_r_squared <- summary(model_test)$adj.r.squared
  bic_result <- BIC(model_test)
    
  # store results
  results[[paste(var1, var2, var3, sep = "_")]] <- list(adj_r_squared = adj_r_squared, BIC = bic_result)
    
  return(results)
}

dependent_var <- "Recent.Close.Price"
# shoutout R for having a free permutation generator
pairs <- combn(quantitative_vars, 2, simplify = FALSE)
# run the function
results <- compare_models(model_data, dependent_var, pairs)

# Print results
print("Adjusted R-squared  and BIC values for all pairs:")
print(results)

```

After Conducting a test of all possible permutations it looks like a model with all three of them having squared and cubed terms is the model that has the highest adjusted R^2 value with the lowest BIC model so we will proceed with this for now. The one worry I have is that I am artifically increasing R^2 by adding more variables, but since I am adjusted R^2 and BIC, I think it is fine. 
### Summary of Model after testing for model misspecification
```{r model 4}
poly_terms <- c()
for (var in quantitative_vars) {
  poly_terms <- c(poly_terms, paste0("I(", var, "^2)"), paste0("I(", var, "^3)"))
}
selected_vars <- c(quantitative_vars, factor_vars, poly_terms)

formula_test <- as.formula(paste("Recent.Close.Price ~", paste(selected_vars, collapse = " + ")))
      

model_4 <- lm(formula_test, data = model_data)
par(mfrow = c(2, 2))  # Reset plotting area
plot(model_4, main = "Model 4")
print(BIC(model_4))
summary(model_4)

```

As of now this appears to be our best model although it does reduce the importance of the market_cap classification it is still the highest R^2 model we have. We will proceed with it as our fourth possible model, and perform tests to see if we need interaction terms with it. It has an adjusted r^2 of 0.7597781 with a BIC of 4896.824. 
## Testing for Need of interaction terms
```{r testing for need of interaction terms}
# Function to test if interaction terms are needed
test_interaction_terms <- function(data, dependent_var, selected_vars) {
  results <- data.frame(
    model = character(),
    var1 = character(),
    var2 = character(),
    adj_r_squared = numeric(),
    AIC = numeric(),
    BIC = numeric(),
    stringsAsFactors = FALSE
  )
  
  # Define base model formula
  base_formula <- as.formula(paste(dependent_var, "~", paste(selected_vars, collapse = " + ")))
  
  # Fit base model
  base_model <- lm(base_formula, data = data)
  
  # Extract adjusted R-squared, AIC, and BIC for base model
  base_adj_r_squared <- summary(base_model)$adj.r.squared
  base_aic <- AIC(base_model)
  base_bic <- BIC(base_model)
  
  # Store base model results
  results <- rbind(results, data.frame(
    model = "base_model",
    var1 = NA,
    var2 = NA,
    adj_r_squared = base_adj_r_squared,
    AIC = base_aic,
    BIC = base_bic,
    stringsAsFactors = FALSE
  ))
  
  # Generate all possible pairs of selected variables for interaction terms
  pairs <- combn(selected_vars, 2, simplify = FALSE)
  
  for (pair in pairs) {
    # i was getting duplicate this elimates it (still computationally longer but too lazy to figure out optimizations)
    pair <- sort(pair)
    var1 <- pair[1]
    var2 <- pair[2]
    
    # Define formula with interaction term
    interaction_formula <- as.formula(paste(dependent_var, "~", 
                                            paste(selected_vars, collapse = " + "), 
                                            "+", paste(var1, "*", var2)))
    
    # Fit model with interaction term
    interaction_model <- lm(interaction_formula, data = data)
    
    # Extract adjusted R-squared, AIC, and BIC for interaction model
    interaction_adj_r_squared <- summary(interaction_model)$adj.r.squared
    interaction_aic <- AIC(interaction_model)
    interaction_bic <- BIC(interaction_model)
    
    # Store interaction model results
    results <- rbind(results, data.frame(
      model = paste(var1, var2, sep = "_"),
      var1 = var1,
      var2 = var2,
      adj_r_squared = interaction_adj_r_squared,
      AIC = interaction_aic,
      BIC = interaction_bic,
      stringsAsFactors = FALSE
    ))
  }
  
  return(results)
}

# Example usage
dependent_var <- "Recent.Close.Price"

# Test for interaction terms
interaction_results <- test_interaction_terms(model_data, dependent_var, selected_vars)
interaction_results <- sort_by(interaction_results, interaction_results$BIC)

# we need to remove all instance of eps and p.e.ratio being interaction variables because the product of those is just the share price making the entire model useless. So this is why i am removing them from potential interaction terms. 
interaction_results <- helper.remove_specific_rows(interaction_results, "EPS", "P.E.Ratio")
# Print results
print("Model comparison results with interaction terms:")

print(interaction_results)
```
I think that I could potentially extrapolate this formula to get to 3 level interaction variables and test multiple 2 way interactions but I feel this would be an infinitely regressive approach and am just going to proceed with the top model as my best model for now (model5). I am worried about overfitting when trying mutiple 2 way interactions and increased complexity. 3 way interaction variables are just things that I have never seen in all my years of doing stats so I will not proceed with that approach.

### Finalizing Model 5
```{r Model 5}
interaction_formula <- as.formula(paste(dependent_var, "~", 
                                            paste(selected_vars, collapse = " + "), 
                                            "+", paste("EPS", "*", "Growth.vs.Value")))
model_5 <- lm(interaction_formula, data = model_data)
par(mfrow = c(2, 2))  # Reset plotting area
plot(model_5, main = "Model 5")
print(BIC(model_5))
summary(model_5)

    
```

As of now this appears to be our best model although it does reduce the importance of the market_cap classification it is still the highest R^2 model we have. We will proceed with it as our fifth possible model, and perform all comparison tests now with our 5 potential models. (`initial_model`, `model_2`, `model_3`, `model_4`, and now `model_5`). 
## Diagnostic Plots of our 5 models
```{r diagnostic of inital model}
helper.diagnostic_plots(initial_model)
summary(initial_model)
```
```{r diagnostic of model 2}
helper.diagnostic_plots(model_2)
summary(model_2)
```


```{r diagnostic of model 3}
helper.diagnostic_plots(model_3)
summary(model_3)
```

```{r diagnostic of model 4}
helper.diagnostic_plots(model_4)
summary(model_4)
```

```{r diagnostic of model 5}
helper.diagnostic_plots(model_5)
summary(model_5)
```

## Model Selection through AIC and BIC and Cross Validation
```{r Model Selction}
# Compare AIC and BIC across models
compare_models <- function(models) {
  results <- data.frame(
    model = names(models),
    AIC = sapply(models, AIC),
    BIC = sapply(models, BIC)
  )
  return(results[order(results$AIC), ])
}

# Example usage
models <- list(model_1 = initial_model, model_2 = model_2, model_3 = model_3, model_4 = model_4, model_5 = model_5)
compare_models(models)

```
### Cross Validation
```{r cross validation}

cross_validate_model <- function(model, data, model_name, k = 10) {
  control <- trainControl(method = "cv", number = k)
  cv_model <- train(formula(model), data = data, method = "lm", trControl = control)
  results <- cv_model$results
  results$model <- model_name
  return(results)
}

# I wanted to return as a dataframe so i did like this instead of printing out each one
cv_results_list <- list()

cv_results_list[[1]] <- cross_validate_model(model_5, model_data, "Model 5")
cv_results_list[[2]] <- cross_validate_model(model_4, model_data, "Model 4")
cv_results_list[[3]] <- cross_validate_model(model_3, model_data, "Model 3")
cv_results_list[[4]] <- cross_validate_model(model_2, stock_data, "Model 2")
cv_results_list[[5]] <- cross_validate_model(initial_model, stock_data, "Initial Model")

cv_results_df <- do.call(rbind, cv_results_list)
print(cv_results_df)

```
I will be choosing model_5 as our model and will proceed with it for all future tests and bootstrapping. This was known before, but I wanted to confirm that it was the best model. This is because it has the lowest AIC and BIC scores while at the same time having the lowest MAE score. Although it has a high RMSE, I am willing to overlook this because of its high performance in R^2, AIC, and BIC. This does raise questions about overfitting however as the cross-validation test is non-deterministic. 
## Testing/Bootstrapping of Model 5
### Multicollinearity Testing
```{r VIF for model 5}
vif_values <- vif(model_5, type = "predictor")
print(vif_values)
```

The VIF test shows that there is no multicollinearity between our predictor variables. Obviously the polynomial and interaction_variable are going to be correlated which is why we use type "predictor" only. None of the values are greater than 5 so no multicollinearity.
### Marginal Effects Estimated
```{r marginal effects}
coefs <- coef(model_5)
marginal_effects <- coefs[-1]  # for some reason in R this means all but the first (this language drives me insane)
barplot(
  marginal_effects,
  main = "Marginal Effects of Predictors",
  ylab = "Marginal Effects",
  las = 2,
  col = "skyblue",
  horiz = FALSE
)

effects_model_5 <- allEffects(model_5)
filtered_effects <- effects_model_5[!grepl("\\^", names(effects_model_5))]
# R HAS THE WORST ITERATOR SYNTAX I HAVE EVER SEEN :(((
for (i in seq_along(filtered_effects)) {
  effect <- filtered_effects[i]
  plot(effect)
}


print(data.frame(Variable = names(marginal_effects), MarginalEffect = marginal_effects))


```

As we can see from the marginal effects from Effects.allEffects all of them are nicely linear except for `P.B.Ratio` and `P.E.Ratio`. A smooth, non-linear relationship between the variables and Recent.Close.Price is observed. The effect of the variables increases and decreases at a non-constant rate as they change, suggesting that a linear model does not adequately capture the complexity of this relationship. We do have quadratic and cubic terms of these variables allowing me to feel comfortable with proceeding with this model and not excluding these variables. Additionally we already tested a model without the linear versions of these terms and it had a lower BIC score suggesting the current version of the model is still statistically significant.
### Boostrapping
``` {r bootstrapping}
n_boot <- 1000  # Number of bootstrap samples
# we will create vectors to store all of the values that we need
alpha_b <- numeric(n_boot)  # Intercept
beta_b <- numeric(n_boot)   # Slope
d_alpha_b <- numeric(n_boot)  # Confidence interval width for intercept
d_beta_b <- numeric(n_boot)   # Confidence interval width for slope
bootstrap_r2 <- numeric(n_boot)  # Storage for R² values

# Perform bootstrapping
set.seed(123)  # For reproducibility
for (i in 1:n_boot) {
  # Resample data with replacement
  boot_indices <- sample(1:nrow(stock_data), nrow(stock_data), replace = TRUE)
  boot_sample <- stock_data[boot_indices, ]
  
  # Fit the OLS model on the bootstrap sample
  
  reg_result <- lm(interaction_formula, data = boot_sample)
  
  # Store the intercept and slope coefficients
  alpha_b[i] <- reg_result$coefficients[1]
  beta_b[i] <- reg_result$coefficients[2]
  
  # Calculate and store confidence intervals
  ci <- confint(reg_result, level = 0.95)
  d_alpha_b[i] <- ci[1, 2] - ci[1, 1]  # Width of confidence interval for intercept
  d_beta_b[i] <- ci[2, 2] - ci[2, 1]   # Width of confidence interval for slope
  
  # Store R²
  bootstrap_r2[i] <- summary(reg_result)$r.squared
}

# Set up plotting area
par(mfrow = c(2, 3))  # 2 rows, 3 columns for the plots

# Plot distribution of the intercept
hist(alpha_b, main = "Bootstrap Intercept", xlab = "Intercept", col = "lightblue", breaks = 30)

# Plot distribution of the slope
hist(beta_b, main = "Bootstrap Slope", xlab = "Slope", col = "lightgreen", breaks = 30)

# Plot distribution of confidence interval widths for intercept
hist(d_alpha_b, main = "CI Width for Intercept", xlab = "CI Width", col = "lightpink", breaks = 30)

# Plot distribution of confidence interval widths for slope
hist(d_beta_b, main = "CI Width for Slope", xlab = "CI Width", col = "lightyellow", breaks = 30)

# Plot distribution of R² values
hist(bootstrap_r2, main = "Bootstrap R²", xlab = "R²", col = "lightcoral", breaks = 30)

# Residuals plot for the original model
plot(fitted(model_5), resid(model_5), main = "Residuals vs Fitted", 
     xlab = "Fitted Values", ylab = "Residuals", col = "blue")
abline(h = 0, col = "red", lty = 2)
```
The bootstrapping results show stable estimates for the intercept, slope, and R^2, with narrow confidence intervals for both the slope and intercept. The model appears well-specified, with no major patterns in the residuals. With this I will conclude testing for our model and proceed to the Summary.

# Summary
```{r summary}
summary(model_5)
```

The objective of this analysis was to develop a model that predicts stock prices based on various financial variables. The results show that EPS, P/E ratio, and P/B ratio are the most influential factors on stock price, with higher values of these variables generally leading to higher stock prices. Specifically, a one-unit increase in EPS is associated with a rise of 33.61 in the stock's recent close price, while higher P/E and P/B ratios also positively affect the stock price, albeit at a diminishing rate due to the inclusion of quadratic and cubic terms for these predictors. This suggests that extreme values of EPS and P/E ratios lead to diminishing returns, indicating that higher profitability and market valuation are not always linearly related to stock price increases. The Growth vs. Value classification also plays a role, with growth stocks commanding higher prices, showing that investors tend to value growth potential more than current book value. It was interesting to note that market cap was not as important as I would have assumed that a small cap stock would automatically indicate a stock price of lower than ~$40 or some other arbritary number.  The interaction term between EPS and Growth vs. Value reveals that the positive effect of EPS on stock price is weaker for growth stocks, suggesting that while EPS is a key driver for stock price, its impact is moderated for growth stocks. The model explains 82% of the variance in stock prices, with the residuals indicating a good fit. I do want to note however this model is probably overfitted and further cross validation should be conducted before anyone uses this in field to inform their stock purchases. We also note from the Cook's plot's from before there is presence of a certain amount of outliers but, we decided to keep them in our final model. It is also interesting to note that the quadratic terms had negative marginal effects while the cubic terms had a positive marginal effect, I am not sure what this means statistically but it is something to point out. 